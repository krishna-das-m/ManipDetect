{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c27857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import neptune\n",
    "import praw\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "Root = Path('.').absolute().parent\n",
    "DATA = Root / r'C:\\Users\\Admin\\Projects\\ML Projects\\ManipDetect\\data'\n",
    "# DATA = Root/ r'C:\\Users\\krishnadas\\Projects\\ML Projects\\ManipDetect\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057a7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_connect():\n",
    "    \"\"\"Initialize Reddit connection\"\"\"\n",
    "    load_dotenv()\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "        client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n",
    "        user_agent=os.getenv('REDDIT_USER_AGENT'),\n",
    "        username=os.getenv('REDDIT_USERNAME'),\n",
    "        password=os.getenv('REDDIT_PASSWORD')\n",
    "    )\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4700021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_update_progress(filename=\"author_update_progress.json\"):\n",
    "    \"\"\"Load previous update progress\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            progress = json.load(f)\n",
    "            return progress.get('completed_ids', set()), progress.get('failed_ids', set())\n",
    "    except FileNotFoundError:\n",
    "        return set(), set()\n",
    "\n",
    "def save_update_progress(completed_ids, failed_ids, filename=\"author_update_progress.json\"):\n",
    "    \"\"\"Save current update progress\"\"\"\n",
    "    progress = {\n",
    "        'completed_ids': list(completed_ids),\n",
    "        'failed_ids': list(failed_ids),\n",
    "        'last_updated': datetime.now().isoformat(),\n",
    "        'total_completed': len(completed_ids),\n",
    "        'total_failed': len(failed_ids)\n",
    "    }\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(progress, f, indent=2)\n",
    "\n",
    "def analyze_csv_file(csv_file):\n",
    "    \"\"\"Analyze the CSV file to understand the data structure\"\"\"\n",
    "    print(f\"Analyzing {csv_file}...\")\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"Total rows: {len(df):,}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Check for post_id column\n",
    "    if 'post_id' not in df.columns:\n",
    "        print(\"ERROR: 'post_id' column not found!\")\n",
    "        print(\"Available columns:\", list(df.columns))\n",
    "        return None\n",
    "    \n",
    "    # Check for author columns\n",
    "    author_columns = [col for col in df.columns if 'author' in col.lower()]\n",
    "    print(f\"Author-related columns: {author_columns}\")\n",
    "    \n",
    "    # Analyze missing authors\n",
    "    if author_columns:\n",
    "        for col in author_columns:\n",
    "            missing_count = df[col].isna().sum()\n",
    "            empty_count = (df[col] == '').sum()\n",
    "            deleted_count = (df[col] == '[deleted]').sum()\n",
    "            unavailable_count = (df[col] == '[unavailable]').sum()\n",
    "            \n",
    "            print(f\"\\n{col} analysis:\")\n",
    "            print(f\"  Missing (NaN): {missing_count:,}\")\n",
    "            print(f\"  Empty strings: {empty_count:,}\")\n",
    "            print(f\"  [deleted]: {deleted_count:,}\")\n",
    "            print(f\"  [unavailable]: {unavailable_count:,}\")\n",
    "            \n",
    "            total_to_update = missing_count + empty_count + unavailable_count\n",
    "            print(f\"  Total to potentially update: {total_to_update:,}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def identify_posts_to_update(df, target_column='author_id'):\n",
    "    \"\"\"Identify which posts need author updates\"\"\"\n",
    "    if target_column not in df.columns:\n",
    "        print(f\"Column '{target_column}' not found. Available columns: {list(df.columns)}\")\n",
    "        return []\n",
    "    \n",
    "    # Posts that need updating\n",
    "    needs_update = df[\n",
    "        df[target_column].isna() |\n",
    "        (df[target_column] == '') |\n",
    "        (df[target_column] == '[unavailable]')\n",
    "    ]\n",
    "    \n",
    "    print(f\"Posts needing author updates: {len(needs_update):,}\")\n",
    "    return needs_update['post_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113a6d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comms_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f020cc86-a54c-4eb8-ad76-a2fe66e611c0",
       "rows": [
        [
         "0",
         "It's not about the money, it's about sending a message. üöÄüíéüôå",
         "55",
         "l6ulcx",
         "https://v.redd.it/6j75regs72e61",
         "6",
         "1611862661.0",
         null,
         "2021-01-28 21:37:41"
        ],
        [
         "1",
         "Math Professor Scott Steiner says the numbers spell DISASTER for Gamestop shorts",
         "110",
         "l6uibd",
         "https://v.redd.it/ah50lyny62e61",
         "23",
         "1611862330.0",
         null,
         "2021-01-28 21:32:10"
        ],
        [
         "2",
         "Exit the system",
         "0",
         "l6uhhn",
         "https://www.reddit.com/r/wallstreetbets/comments/l6uhhn/exit_the_system/",
         "47",
         "1611862235.0",
         "The CEO of NASDAQ pushed to halt trading ‚Äúto give investors a chance to recalibrate their positions‚Äù.\n\n[https://mobile.twitter.com/Mediaite/status/1354504710695362563](https://mobile.twitter.com/Mediaite/status/1354504710695362563)\n\nNow SEC is investigating, brokers are disallowing buying more calls. This is the institutions flat out admitting they will change the rules to bail out the rich but if it happens to us, we get a ‚Äúwell shucks you should have known investing is risky! have you tried cutting out avocados and coffee, maybe doing Uber on the side?‚Äù\n\nWe may have collectively driven up enough sentiment in wall street to make other big players go long on GME with us (we do not have the money to move the stock as much as it did alone). we didn‚Äôt hurt wall street as a whole, just a few funds went down while others went up and profited off the shorts the same as us. The media wants to pin the blame on us.\n\nIt should be crystal clear that this is a rigged game by now. Its time to build new exchanges that can‚Äôt arbitrarily change the rules on us. Cr\\*\\*o has some version of these, maybe they can be repurposed to be trade stock without government intervention. I don‚Äôt know exactly what it will look like yet, but the broad next steps i see are - 1. exit the current financial system 2. build a new one.",
         "2021-01-28 21:30:35"
        ],
        [
         "3",
         "NEW SEC FILING FOR GME! CAN SOMEONE LESS RETARDED THAN ME PLEASE INTERPRET?",
         "29",
         "l6ugk6",
         "https://sec.report/Document/0001193125-21-019848/",
         "74",
         "1611862137.0",
         null,
         "2021-01-28 21:28:57"
        ],
        [
         "4",
         "Not to distract from GME, just thought our AMC brothers should be aware of this",
         "71",
         "l6ufgy",
         "https://i.redd.it/4h2sukb662e61.jpg",
         "156",
         "1611862016.0",
         null,
         "2021-01-28 21:26:56"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "      <td>55</td>\n",
       "      <td>l6ulcx</td>\n",
       "      <td>https://v.redd.it/6j75regs72e61</td>\n",
       "      <td>6</td>\n",
       "      <td>1.611863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:37:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>l6uibd</td>\n",
       "      <td>https://v.redd.it/ah50lyny62e61</td>\n",
       "      <td>23</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exit the system</td>\n",
       "      <td>0</td>\n",
       "      <td>l6uhhn</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>The CEO of NASDAQ pushed to halt trading ‚Äúto g...</td>\n",
       "      <td>2021-01-28 21:30:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>l6ugk6</td>\n",
       "      <td>https://sec.report/Document/0001193125-21-019848/</td>\n",
       "      <td>74</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>l6ufgy</td>\n",
       "      <td>https://i.redd.it/4h2sukb662e61.jpg</td>\n",
       "      <td>156</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0  It's not about the money, it's about sending a...     55  l6ulcx   \n",
       "1  Math Professor Scott Steiner says the numbers ...    110  l6uibd   \n",
       "2                                    Exit the system      0  l6uhhn   \n",
       "3  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29  l6ugk6   \n",
       "4  Not to distract from GME, just thought our AMC...     71  l6ufgy   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0                    https://v.redd.it/6j75regs72e61          6  1.611863e+09   \n",
       "1                    https://v.redd.it/ah50lyny62e61         23  1.611862e+09   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         47  1.611862e+09   \n",
       "3  https://sec.report/Document/0001193125-21-019848/         74  1.611862e+09   \n",
       "4                https://i.redd.it/4h2sukb662e61.jpg        156  1.611862e+09   \n",
       "\n",
       "                                                body            timestamp  \n",
       "0                                                NaN  2021-01-28 21:37:41  \n",
       "1                                                NaN  2021-01-28 21:32:10  \n",
       "2  The CEO of NASDAQ pushed to halt trading ‚Äúto g...  2021-01-28 21:30:35  \n",
       "3                                                NaN  2021-01-28 21:28:57  \n",
       "4                                                NaN  2021-01-28 21:26:56  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = DATA / 'reddit_wsb.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c91f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['author_name'] = None\n",
    "# df['author_id'] = None\n",
    "# # chnage id column to post id\n",
    "# df.rename(columns={'id': 'post_id'}, inplace=True)\n",
    "# df.to_csv(DATA / 'new_reddit_wsb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656a12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_authors_bulk(csv_file, target_column='author_name', batch_size=100, test_mode=False, test_limit=100):\n",
    "    \"\"\"Update authors in bulk with progress tracking and resume capability\"\"\"\n",
    "    \n",
    "    # Load environment variables\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Initialize Neptune for tracking\n",
    "    run = neptune.init_run(project=\"krishnadasm/wallstreetbets-scraper\")\n",
    "    run[\"config/task\"] = \"author_update\"\n",
    "    run[\"config/csv_file\"] = csv_file\n",
    "    run[\"config/target_column\"] = target_column\n",
    "    run[\"config/batch_size\"] = batch_size\n",
    "    run[\"config/test_mode\"] = test_mode\n",
    "    if test_mode:\n",
    "        run[\"config/test_limit\"] = test_limit\n",
    "    \n",
    "    # Initialize Reddit\n",
    "    reddit = reddit_connect()\n",
    "    \n",
    "    # Load and analyze CSV\n",
    "    df = analyze_csv_file(csv_file)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Identify posts to update\n",
    "    posts_to_update = identify_posts_to_update(df, target_column)\n",
    "    \n",
    "    if not posts_to_update:\n",
    "        print(\"No posts need updating!\")\n",
    "        run.stop()\n",
    "        return\n",
    "    \n",
    "    # TEST MODE: Limit to first N posts\n",
    "    if test_mode:\n",
    "        posts_to_update = posts_to_update[:test_limit]\n",
    "        print(f\"üß™ TEST MODE: Limited to {len(posts_to_update)} posts\")\n",
    "    \n",
    "    # Load previous progress (skip in test mode)\n",
    "    if not test_mode:\n",
    "        completed_ids, failed_ids = load_update_progress()\n",
    "        remaining_posts = [pid for pid in posts_to_update if pid not in completed_ids]\n",
    "    else:\n",
    "        completed_ids, failed_ids = set(), set()\n",
    "        remaining_posts = posts_to_update\n",
    "    \n",
    "    print(f\"Total posts to update: {len(posts_to_update):,}\")\n",
    "    if not test_mode:\n",
    "        print(f\"Already completed: {len(completed_ids):,}\")\n",
    "    print(f\"Remaining: {len(remaining_posts):,}\")\n",
    "    \n",
    "    # Log initial stats to Neptune\n",
    "    run[\"stats/total_posts_to_update\"] = len(posts_to_update)\n",
    "    run[\"stats/already_completed\"] = len(completed_ids)\n",
    "    run[\"stats/remaining\"] = len(remaining_posts)\n",
    "    \n",
    "    # Estimate time\n",
    "    if test_mode:\n",
    "        estimated_minutes = len(remaining_posts) / 60  # ~1 post per second with delays\n",
    "        print(f\"Estimated time: {estimated_minutes:.1f} minutes\")\n",
    "    else:\n",
    "        estimated_hours = len(remaining_posts) / 3600  # ~1 post per second with delays\n",
    "        print(f\"Estimated time: {estimated_hours:.1f} hours\")\n",
    "    \n",
    "    # Start updating\n",
    "    start_time = time.time()\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    try:\n",
    "        # Process in batches\n",
    "        for i in range(0, len(remaining_posts), batch_size):\n",
    "            batch = remaining_posts[i:i+batch_size]\n",
    "            \n",
    "            print(f\"\\nProcessing batch {i//batch_size + 1}/{(len(remaining_posts) + batch_size - 1)//batch_size}\")\n",
    "            \n",
    "            for post_id in tqdm(batch, desc=\"Updating authors\"):\n",
    "                try:\n",
    "                    # Get submission\n",
    "                    submission = reddit.submission(id=post_id)\n",
    "                    \n",
    "                    # Get author info (both name and ID)\n",
    "                    if submission.author is not None:\n",
    "                        author_name = submission.author.name\n",
    "                        author_id = submission.author.id\n",
    "                    else:\n",
    "                        author_name = \"[deleted]\"\n",
    "                        author_id = \"[deleted]\"\n",
    "                    \n",
    "                    # Update dataframe\n",
    "                    mask = df['post_id'] == post_id\n",
    "                    df.loc[mask, target_column] = author_name\n",
    "                    \n",
    "                    # Add author_id column if it doesn't exist\n",
    "                    if 'author_id' not in df.columns:\n",
    "                        df['author_id'] = None\n",
    "                    df.loc[mask, 'author_id'] = author_id\n",
    "                    \n",
    "                    completed_ids.add(post_id)\n",
    "                    success_count += 1\n",
    "                    \n",
    "                    # In test mode, show detailed results\n",
    "                    if test_mode and success_count <= 10:\n",
    "                        print(f\"  ‚úÖ {post_id}: {author_name} (ID: {author_id})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ùå Error updating post {post_id}: {e}\")\n",
    "                    failed_ids.add(post_id)\n",
    "                    error_count += 1\n",
    "                \n",
    "                # Rate limiting (shorter delay in test mode)\n",
    "                if test_mode:\n",
    "                    time.sleep(0.5)  # Faster for testing\n",
    "                else:\n",
    "                    time.sleep(1.1)  # Conservative for production\n",
    "            \n",
    "            # Save progress after each batch (skip in test mode)\n",
    "            if not test_mode:\n",
    "                save_update_progress(completed_ids, failed_ids)\n",
    "            \n",
    "            # Save intermediate CSV\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            if test_mode:\n",
    "                temp_filename = f\"test_updated_{timestamp}.csv\"\n",
    "            else:\n",
    "                temp_filename = f\"temp_updated_{timestamp}.csv\"\n",
    "            df.to_csv(temp_filename, index=False)\n",
    "            \n",
    "            # Log progress to Neptune\n",
    "            run[\"progress/completed\"].log(len(completed_ids))\n",
    "            run[\"progress/failed\"].log(len(failed_ids))\n",
    "            run[\"progress/success_rate\"].log(success_count / (success_count + error_count) if (success_count + error_count) > 0 else 0)\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            posts_per_minute = len(completed_ids) / (elapsed_time / 60) if elapsed_time > 0 else 0\n",
    "            run[\"progress/posts_per_minute\"].log(posts_per_minute)\n",
    "            \n",
    "            print(f\"Progress: {len(completed_ids):,}/{len(posts_to_update):,} ({len(completed_ids)/len(posts_to_update)*100:.1f}%)\")\n",
    "            print(f\"Success rate: {success_count}/{success_count + error_count} ({success_count/(success_count + error_count)*100:.1f}%)\")\n",
    "            print(f\"Posts per minute: {posts_per_minute:.1f}\")\n",
    "            \n",
    "            # Shorter break in test mode\n",
    "            if i + batch_size < len(remaining_posts):\n",
    "                if test_mode:\n",
    "                    print(\"Taking a 5-second break...\")\n",
    "                    time.sleep(5)\n",
    "                else:\n",
    "                    print(\"Taking a 30-second break between batches...\")\n",
    "                    time.sleep(30)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nUpdate interrupted by user. Progress saved.\")\n",
    "        run[\"status\"] = \"interrupted\"\n",
    "        run[\"interruption_point\"] = len(completed_ids)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        run[\"status\"] = \"error\"\n",
    "        run[\"error_message\"] = str(e)\n",
    "    \n",
    "    finally:\n",
    "        # Final save\n",
    "        if not test_mode:\n",
    "            save_update_progress(completed_ids, failed_ids)\n",
    "        \n",
    "        # Save final CSV\n",
    "        if test_mode:\n",
    "            final_filename = Path(str(csv_file).replace(\".csv\", \"_test_with_authors.csv\"))\n",
    "        else:\n",
    "            final_filename = Path(str(csv_file).replace('.csv', '_with_authors.csv'))\n",
    "        df.to_csv(final_filename, index=False)\n",
    "        \n",
    "        # Calculate final stats\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        \n",
    "        print(f\"\\nUpdate completed!\")\n",
    "        if test_mode:\n",
    "            print(f\"Total time: {total_time/60:.2f} minutes\")\n",
    "        else:\n",
    "            print(f\"Total time: {total_time/3600:.2f} hours\")\n",
    "        print(f\"Successfully updated: {success_count:,}\")\n",
    "        print(f\"Failed: {error_count:,}\")\n",
    "        print(f\"Final CSV saved as: {final_filename}\")\n",
    "        \n",
    "        # Show sample of updated data in test mode\n",
    "        if test_mode and success_count > 0:\n",
    "            print(f\"\\nüìä Sample of updated data:\")\n",
    "            sample_data = df[df['post_id'].isin(list(completed_ids)[:5])]\n",
    "            for _, row in sample_data.iterrows():\n",
    "                print(f\"  {row['post_id']}: '{row['title'][:50]}...' by {row[target_column]} (ID: {row['author_id']})\")\n",
    "        \n",
    "        # Log final results to Neptune\n",
    "        run[\"results/total_time_hours\"] = total_time / 3600\n",
    "        run[\"results/successfully_updated\"] = success_count\n",
    "        run[\"results/failed_updates\"] = error_count\n",
    "        run[\"results/final_csv\"] = str(final_filename)\n",
    "        \n",
    "        # Upload final CSV to Neptune\n",
    "        run[\"data/updated_csv\"].upload(str(final_filename))\n",
    "        if not test_mode:\n",
    "            run[\"data/progress_file\"].upload(\"author_update_progress.json\")\n",
    "        \n",
    "        run.stop()\n",
    "        \n",
    "        return df\n",
    "\n",
    "def resume_update(csv_file, target_column='author_name'):\n",
    "    \"\"\"Resume a previously interrupted update\"\"\"\n",
    "    print(\"Resuming previous update...\")\n",
    "    return update_authors_bulk(csv_file, target_column)\n",
    "\n",
    "def quick_stats(csv_file):\n",
    "    \"\"\"Get quick statistics about the CSV file\"\"\"\n",
    "    df = analyze_csv_file(csv_file)\n",
    "    if df is not None:\n",
    "        posts_to_update = identify_posts_to_update(df)\n",
    "        print(f\"\\nQuick Stats:\")\n",
    "        print(f\"Total posts: {len(df):,}\")\n",
    "        print(f\"Posts needing author updates: {len(posts_to_update):,}\")\n",
    "        print(f\"Estimated time: {len(posts_to_update)/3600:.1f} hours\")\n",
    "\n",
    "def test_author_update(csv_file, target_column='author_name', test_limit=100):\n",
    "    \"\"\"Test author update with a small sample first\"\"\"\n",
    "    print(f\"üß™ TESTING MODE: Updating {test_limit} posts\")\n",
    "    print(\"=\" * 50)\n",
    "    return update_authors_bulk(csv_file, target_column, test_mode=True, test_limit=test_limit)\n",
    "\n",
    "def production_author_update(csv_file, target_column='author_name'):\n",
    "    \"\"\"Run full production update\"\"\"\n",
    "    print(\"üöÄ PRODUCTION MODE: Updating all missing authors\")\n",
    "    print(\"=\" * 50)\n",
    "    return update_authors_bulk(csv_file, target_column, test_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083454ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß WSB Author Updater Script\n",
      "==================================================\n",
      "Step 1: Analyzing your CSV file...\n",
      "Analyzing C:\\Users\\Admin\\Projects\\ML Projects\\ManipDetect\\data\\new_reddit_wsb.csv...\n",
      "Total rows: 53,187\n",
      "Columns: ['title', 'score', 'post_id', 'url', 'comms_num', 'created', 'body', 'timestamp', 'author_name', 'author_id']\n",
      "Author-related columns: ['author_name', 'author_id']\n",
      "\n",
      "author_name analysis:\n",
      "  Missing (NaN): 53,187\n",
      "  Empty strings: 0\n",
      "  [deleted]: 0\n",
      "  [unavailable]: 0\n",
      "  Total to potentially update: 53,187\n",
      "\n",
      "author_id analysis:\n",
      "  Missing (NaN): 53,187\n",
      "  Empty strings: 0\n",
      "  [deleted]: 0\n",
      "  [unavailable]: 0\n",
      "  Total to potentially update: 53,187\n",
      "Posts needing author updates: 53,187\n",
      "\n",
      "Quick Stats:\n",
      "Total posts: 53,187\n",
      "Posts needing author updates: 53,187\n",
      "Estimated time: 14.8 hours\n",
      "\n",
      "==================================================\n",
      "Choose your action:\n",
      "1. Test Mode (100 posts) - Uncomment line below\n",
      "2. Production Mode (all posts) - Uncomment line below\n",
      "3. Resume interrupted update - Uncomment line below\n",
      "==================================================\n",
      "üöÄ PRODUCTION MODE: Updating all missing authors\n",
      "==================================================\n",
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/krishnadasm/wallstreetbets-scraper/e/WAL-19\n",
      "Analyzing C:\\Users\\Admin\\Projects\\ML Projects\\ManipDetect\\data\\new_reddit_wsb.csv...\n",
      "Total rows: 53,187\n",
      "Columns: ['title', 'score', 'post_id', 'url', 'comms_num', 'created', 'body', 'timestamp', 'author_name', 'author_id']\n",
      "Author-related columns: ['author_name', 'author_id']\n",
      "\n",
      "author_name analysis:\n",
      "  Missing (NaN): 53,187\n",
      "  Empty strings: 0\n",
      "  [deleted]: 0\n",
      "  [unavailable]: 0\n",
      "  Total to potentially update: 53,187\n",
      "\n",
      "author_id analysis:\n",
      "  Missing (NaN): 53,187\n",
      "  Empty strings: 0\n",
      "  [deleted]: 0\n",
      "  [unavailable]: 0\n",
      "  Total to potentially update: 53,187\n",
      "Posts needing author updates: 53,187\n",
      "Total posts to update: 53,187\n",
      "Already completed: 0\n",
      "Remaining: 53,187\n",
      "Estimated time: 14.8 hours\n",
      "\n",
      "Processing batch 1/532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:   0%|          | 0/100 [00:00<?, ?it/s]C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8808\\1706575410.py:91: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[deleted]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, target_column] = author_name\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8808\\1706575410.py:96: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[deleted]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, 'author_id'] = author_id\n",
      "Updating authors:  16%|‚ñà‚ñå        | 16/100 [00:41<02:48,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6u5j2: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [01:26<02:44,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6tke3: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [01:43<02:30,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6tauf: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [02:50<01:12,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6s675: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [04:10<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 96/53,187 (0.2%)\n",
      "Success rate: 96/100 (96.0%)\n",
      "Posts per minute: 22.9\n",
      "Taking a 30-second break between batches...\n",
      "\n",
      "Processing batch 2/532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [01:52<02:32,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6o2gi: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [01:58<03:33,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6o19x: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [02:07<03:19,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6nqz9: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [02:26<03:06,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6nfh1: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [03:47<01:47,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6l6b2: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [04:12<01:15,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6kgq9: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [04:34<01:02,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6k1j5: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [04:51<00:18,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6jr5f: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [05:15<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 188/53,187 (0.4%)\n",
      "Success rate: 188/200 (94.0%)\n",
      "Posts per minute: 18.8\n",
      "Taking a 30-second break between batches...\n",
      "\n",
      "Processing batch 3/532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:   4%|‚ñç         | 4/100 [00:10<03:38,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6jdu8: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  15%|‚ñà‚ñå        | 15/100 [00:38<02:44,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6hczl: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [02:55<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 286/53,187 (0.5%)\n",
      "Success rate: 286/300 (95.3%)\n",
      "Posts per minute: 21.3\n",
      "Taking a 30-second break between batches...\n",
      "\n",
      "Processing batch 4/532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  20%|‚ñà‚ñà        | 20/100 [00:31<02:08,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6x1jt: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [02:13<00:35,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6x11d: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [02:44<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 384/53,187 (0.7%)\n",
      "Success rate: 384/400 (96.0%)\n",
      "Posts per minute: 23.0\n",
      "Taking a 30-second break between batches...\n",
      "\n",
      "Processing batch 5/532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  14%|‚ñà‚ñç        | 14/100 [00:22<02:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6x0wm: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [01:18<01:22,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6x0he: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [02:37<00:01,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6wzzm: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [02:39<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 481/53,187 (0.9%)\n",
      "Success rate: 481/500 (96.2%)\n",
      "Posts per minute: 24.2\n",
      "Taking a 30-second break between batches...\n",
      "\n",
      "Processing batch 6/532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  11%|‚ñà         | 11/100 [00:17<02:24,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6wzxp: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [02:39<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 580/53,187 (1.1%)\n",
      "Success rate: 580/600 (96.7%)\n",
      "Posts per minute: 25.2\n",
      "Taking a 30-second break between batches...\n",
      "\n",
      "Processing batch 7/532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [02:30<00:07,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6wyfx: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [02:38<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 679/53,187 (1.3%)\n",
      "Success rate: 679/700 (97.0%)\n",
      "Posts per minute: 25.9\n",
      "Taking a 30-second break between batches...\n",
      "\n",
      "Processing batch 8/532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:   8%|‚ñä         | 8/100 [00:12<02:27,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6wydb: received 404 HTTP response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  13%|‚ñà‚ñé        | 13/100 [00:20<02:17,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6wyc5: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  22%|‚ñà‚ñà‚ñè       | 22/100 [00:35<02:15,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6wyap: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [01:28<01:10,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ùå Error updating post l6wxyd: 'Redditor' object has no attribute 'id'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating authors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [02:40<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 775/53,187 (1.5%)\n",
      "Success rate: 775/800 (96.9%)\n",
      "Posts per minute: 26.4\n",
      "Taking a 30-second break between batches...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    CSV_FILE = DATA/\"new_reddit_wsb.csv\"  # Replace with your actual CSV file\n",
    "    TARGET_COLUMN = \"author_name\"  # Column to update\n",
    "    \n",
    "    print(\"üîß WSB Author Updater Script\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Get quick statistics first\n",
    "    print(\"Step 1: Analyzing your CSV file...\")\n",
    "    quick_stats(CSV_FILE)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Choose your action:\")\n",
    "    print(\"1. Test Mode (100 posts) - Uncomment line below\")\n",
    "    print(\"2. Production Mode (all posts) - Uncomment line below\")\n",
    "    print(\"3. Resume interrupted update - Uncomment line below\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Uncomment ONE of these lines to run:\n",
    "    \n",
    "    # üß™ TEST MODE - Start here to test with 100 posts\n",
    "    # test_author_update(CSV_FILE, TARGET_COLUMN, test_limit=100)\n",
    "    \n",
    "    # üöÄ PRODUCTION MODE - Run this after testing works\n",
    "    production_author_update(CSV_FILE, TARGET_COLUMN)\n",
    "    \n",
    "    # üîÑ RESUME MODE - Use this if production run was interrupted\n",
    "    # resume_update(CSV_FILE, TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da523c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "post_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comms_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "created",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "body",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2ef573fa-3d54-498c-b7f3-0aac5a1795b7",
       "rows": [
        [
         "0",
         "It's not about the money, it's about sending a message. üöÄüíéüôå",
         "55",
         "l6ulcx",
         "https://v.redd.it/6j75regs72e61",
         "6",
         "1611862661.0",
         null,
         "2021-01-28 21:37:41",
         "[deleted]",
         "[deleted]"
        ],
        [
         "1",
         "Math Professor Scott Steiner says the numbers spell DISASTER for Gamestop shorts",
         "110",
         "l6uibd",
         "https://v.redd.it/ah50lyny62e61",
         "23",
         "1611862330.0",
         null,
         "2021-01-28 21:32:10",
         "jaxxtothemaxx",
         "onvag"
        ],
        [
         "2",
         "Exit the system",
         "0",
         "l6uhhn",
         "https://www.reddit.com/r/wallstreetbets/comments/l6uhhn/exit_the_system/",
         "47",
         "1611862235.0",
         "The CEO of NASDAQ pushed to halt trading ‚Äúto give investors a chance to recalibrate their positions‚Äù.\n\n[https://mobile.twitter.com/Mediaite/status/1354504710695362563](https://mobile.twitter.com/Mediaite/status/1354504710695362563)\n\nNow SEC is investigating, brokers are disallowing buying more calls. This is the institutions flat out admitting they will change the rules to bail out the rich but if it happens to us, we get a ‚Äúwell shucks you should have known investing is risky! have you tried cutting out avocados and coffee, maybe doing Uber on the side?‚Äù\n\nWe may have collectively driven up enough sentiment in wall street to make other big players go long on GME with us (we do not have the money to move the stock as much as it did alone). we didn‚Äôt hurt wall street as a whole, just a few funds went down while others went up and profited off the shorts the same as us. The media wants to pin the blame on us.\n\nIt should be crystal clear that this is a rigged game by now. Its time to build new exchanges that can‚Äôt arbitrarily change the rules on us. Cr\\*\\*o has some version of these, maybe they can be repurposed to be trade stock without government intervention. I don‚Äôt know exactly what it will look like yet, but the broad next steps i see are - 1. exit the current financial system 2. build a new one.",
         "2021-01-28 21:30:35",
         "stonerbobo",
         "f3p9m"
        ],
        [
         "3",
         "NEW SEC FILING FOR GME! CAN SOMEONE LESS RETARDED THAN ME PLEASE INTERPRET?",
         "29",
         "l6ugk6",
         "https://sec.report/Document/0001193125-21-019848/",
         "74",
         "1611862137.0",
         null,
         "2021-01-28 21:28:57",
         "Sleavitt10",
         "9u7y1"
        ],
        [
         "4",
         "Not to distract from GME, just thought our AMC brothers should be aware of this",
         "71",
         "l6ufgy",
         "https://i.redd.it/4h2sukb662e61.jpg",
         "156",
         "1611862016.0",
         null,
         "2021-01-28 21:26:56",
         "di3_b0ld",
         "13cexg"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>post_id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "      <td>55</td>\n",
       "      <td>l6ulcx</td>\n",
       "      <td>https://v.redd.it/6j75regs72e61</td>\n",
       "      <td>6</td>\n",
       "      <td>1.611863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:37:41</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>l6uibd</td>\n",
       "      <td>https://v.redd.it/ah50lyny62e61</td>\n",
       "      <td>23</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "      <td>jaxxtothemaxx</td>\n",
       "      <td>onvag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exit the system</td>\n",
       "      <td>0</td>\n",
       "      <td>l6uhhn</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>The CEO of NASDAQ pushed to halt trading ‚Äúto g...</td>\n",
       "      <td>2021-01-28 21:30:35</td>\n",
       "      <td>stonerbobo</td>\n",
       "      <td>f3p9m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>l6ugk6</td>\n",
       "      <td>https://sec.report/Document/0001193125-21-019848/</td>\n",
       "      <td>74</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "      <td>Sleavitt10</td>\n",
       "      <td>9u7y1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>l6ufgy</td>\n",
       "      <td>https://i.redd.it/4h2sukb662e61.jpg</td>\n",
       "      <td>156</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "      <td>di3_b0ld</td>\n",
       "      <td>13cexg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score post_id  \\\n",
       "0  It's not about the money, it's about sending a...     55  l6ulcx   \n",
       "1  Math Professor Scott Steiner says the numbers ...    110  l6uibd   \n",
       "2                                    Exit the system      0  l6uhhn   \n",
       "3  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29  l6ugk6   \n",
       "4  Not to distract from GME, just thought our AMC...     71  l6ufgy   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0                    https://v.redd.it/6j75regs72e61          6  1.611863e+09   \n",
       "1                    https://v.redd.it/ah50lyny62e61         23  1.611862e+09   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         47  1.611862e+09   \n",
       "3  https://sec.report/Document/0001193125-21-019848/         74  1.611862e+09   \n",
       "4                https://i.redd.it/4h2sukb662e61.jpg        156  1.611862e+09   \n",
       "\n",
       "                                                body            timestamp  \\\n",
       "0                                                NaN  2021-01-28 21:37:41   \n",
       "1                                                NaN  2021-01-28 21:32:10   \n",
       "2  The CEO of NASDAQ pushed to halt trading ‚Äúto g...  2021-01-28 21:30:35   \n",
       "3                                                NaN  2021-01-28 21:28:57   \n",
       "4                                                NaN  2021-01-28 21:26:56   \n",
       "\n",
       "     author_name  author_id  \n",
       "0      [deleted]  [deleted]  \n",
       "1  jaxxtothemaxx      onvag  \n",
       "2     stonerbobo      f3p9m  \n",
       "3     Sleavitt10      9u7y1  \n",
       "4       di3_b0ld     13cexg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = DATA/\"new_reddit_wsb_test_with_authors.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
